DynamoDB table
=======================================================================================
Terraform uses DynamoDB table (the one you specified: terraform-state-lock) to place a 
lock whenever you run a command (plan, apply, etc.) so that two people (or processes) 
donâ€™t try to update the state at the same time.

===> Manually unlock state file with Terraform
terraform force-unlock <LOCK_ID>

Terraform is still holding on to an old state or the backend configuration wasnâ€™t refreshed.
============================================================================================
- Steps to refresh Terraform with new code
===> Reinitialize Terraform (so it re-reads your updated files):
terraform init -reconfigure

- Validate your new code to make sure there are no syntax errors:
======> terraform validate

- See what Terraform plans to do with the updated code:
=====> terraform plan

- Apply the changes:
=====> terraform apply


================================ Data Sources ==========================================
- In Terraform, there are two main things you work with:

=> 1. Resources â†’ Things Terraform creates or manages.
Example:

resource "aws_db_instance" "mydb" {
  # creates a new RDS instance
}

=> 2. Data Sources â†’ Things Terraform reads / looks up (already exist in AWS) 
so you can use them in your configuration.
Example:

data "aws_db_snapshot" "example" {
  most_recent            = true
  db_instance_identifier = "mydb-instance"
}


- So, what does data "aws_db_snapshot" mean?
It tells Terraform:
ðŸ‘‰ â€œDonâ€™t create a new snapshot. Instead, go and find an existing 
snapshot in AWS and make its information available for me to use.â€


Note
=======================================
- Resource: aws_acm_certificate_validation

resource "aws_acm_certificate" "example" {
  domain_name       = "example.com"
  validation_method = "DNS"
}

data "aws_route53_zone" "example" {
  name         = "example.com"
  private_zone = false
}

resource "aws_route53_record" "example" {
  for_each = {
    for dvo in aws_acm_certificate.example.domain_validation_options : dvo.domain_name => {
      name   = dvo.resource_record_name
      record = dvo.resource_record_value
      type   = dvo.resource_record_type
    }
  }

  allow_overwrite = true
  name            = each.value.name
  records         = [each.value.record]
  ttl             = 60
  type            = each.value.type
  zone_id         = data.aws_route53_zone.example.zone_id
}

resource "aws_acm_certificate_validation" "example" {
  certificate_arn         = aws_acm_certificate.example.arn
  validation_record_fqdns = [for record in aws_route53_record.example : record.fqdn]
}

=============== Why we have one Target Group and two Listeners in your code:==============================================
-1 Target Group (TG)

- A Target Group defines where the traffic will be forwarded (EC2s, ECS tasks, Lambda, etc.)
- this is where your backend instances (EC2, ECS, Lambda, etc.) are registered.

-2 Listener (L)
- A Listener is just a â€œport + protocolâ€ entry point on the load balancer.
- Port 80 (HTTP) â†’ only used to redirect traffic to HTTPS (not to forward traffic to targets).
- Port 443 (HTTPS) â†’ actually forwards requests to the Target Group.

So in practice:
- HTTP (80) â†’ redirects â†’ HTTPS (443).
- HTTPS (443) â†’ forwards to the TG.

Why not two Target Groups?

Because both listeners (after the redirect) end up sending traffic to the same backend (same app servers).

Port 80 is just for redirect, not for serving.

Port 443 is for serving traffic securely.

So only one Target Group is needed unless you want different backends for different condition


================================== acm ( amazon certificate manager ) =====================================
- subject_alternative_names = subdomain name

aws_s3_object
==============================================================================
- aws_s3_object in Terraform

resource "aws_s3_object" "upload_env_file" { 
bucket = aws_s3_bucket.env_file_bucket.id 
key = var.env_file_name 
source = "./${var.env_file_name}" 
}

- => aws_s3_object is a Terraform resource type used to upload and manage 
individual files (objects) in an AWS S3 bucket.

- key â†’ the name/path of the file in S3 (remote)
- source â†’ the name/path of the file on your local machine (local) 

- In S3, the file will be at: s3://your-bucket-name/configs/prod.env
-Locally, Terraform reads the file from ./production.env.

"./${var.env_file_name}" is a relative path:

./ â†’ current working directory (where you run terraform apply)

${var.env_file_name} â†’ the value of the variable env_file_name

===>
resource "aws_s3_object" "upload_env_file" {
  bucket = aws_s3_bucket.env_file_bucket.id
  key    = "configs/production.env"
  source = "./production.env"
  acl    = "private"
}

What happens here:
++===========
-Terraform finds ./production.env on your machine.

-Terraform uploads it to the S3 bucket env_file_bucket.

-Inside S3, it will be stored as configs/production.env.

-The file will be private by default unless you change acl


























